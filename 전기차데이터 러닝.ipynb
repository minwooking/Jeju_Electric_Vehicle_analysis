{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UseLib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "############## 전처리 및 데이터 핸들링 ###############################\n",
    "\n",
    "import numpy as np\n",
    "import  pandas as pd\n",
    "import os\n",
    "from konlpy.tag import Okt \n",
    "okt = Okt()\n",
    "from tqdm.notebook import tqdm\n",
    "import joblib\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import copy\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "\n",
    "############## 머신러닝 모델#########################\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "nb = MultinomialNB()\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression()\n",
    "from sklearn.svm import SVC\n",
    "svc =  SVC()\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn =KNeighborsClassifier()\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc = RandomForestClassifier(random_state=2021)\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "xgc = XGBClassifier()\n",
    "\n",
    "\n",
    "############## 평가 ###############################\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UseData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/miwoos/WorkSpace/GoogleDrive/제주_전기차/data\n"
     ]
    }
   ],
   "source": [
    "cd ~/WorkSpace/GoogleDrive/제주_전기차/data ## 경로이동"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \u001b[0m\u001b[01;35melc_usewordcloud.png\u001b[0m             '전기차 동호회 전기차크롤링.csv'\n",
      " elecafe.csv                       전기차_전처리및토큰화.csv\n",
      " lr.pkl                            전기차관련검색어인기순.csv\n",
      " lrc.pkl                           전기차관심도지역.csv\n",
      " tvect.pkl                         전기차관심증가.csv\n",
      " 관련키워드.csv                    전기차전처리추가.csv\n",
      " 네이버-제주전기차후기통합.csv     전기차키워드관련주제인기순.csv\n",
      " 느영나영전기차크롤링.csv          전체본문의댓글결과_2022.03.06.xlsx\n",
      " 느영나영전기차크롤링.csv.part     제사모크롤링.csv\n",
      "'본문 검색 결과_2022.03.06.xlsx'   투플럭스sjeju.csv\n",
      " \u001b[01;35m빈도수파악.png\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "ls ## 데이터 위치 파악 및 데이터 리스트 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train= pd.read_csv('전기차_전처리및토큰화.csv')\n",
    "df_cafe = pd.read_csv('elecafe.csv')\n",
    "df_Blog = pd.read_csv('네이버-제주전기차후기통합.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 러닝"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 널값 제거 및 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>전처리</th>\n",
       "      <th>평가</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>아이오 닉 휠 베이스 가치 서비스 센터 가다 부품 수급 문제 로 렌터카 받다 오다 ...</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>현대차 아이오 닉 테슬라 모델 뭘 살다 요 현대차 아이오 닉 테슬라 모델 뭘 살다 ...</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 전처리 평가\n",
       "0  아이오 닉 휠 베이스 가치 서비스 센터 가다 부품 수급 문제 로 렌터카 받다 오다 ...  P\n",
       "1  현대차 아이오 닉 테슬라 모델 뭘 살다 요 현대차 아이오 닉 테슬라 모델 뭘 살다 ...  P"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전처리    0\n",
      "평가     0\n",
      "dtype: int64\n",
      "제목      0\n",
      "내용      0\n",
      "댓글      0\n",
      "유형      0\n",
      "조회수     0\n",
      "작성날짜    0\n",
      "월별      0\n",
      "카페명     0\n",
      "년별      0\n",
      "dtype: int64\n",
      "제목      0\n",
      "날짜      0\n",
      "내용      0\n",
      "href    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df_train.isnull().sum())\n",
    "print(df_cafe.isnull().sum())\n",
    "print(df_Blog.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df_Blog['index'] # 인덱스칼럼이 널값이많아서 컬럼 자체를 없애 버림 \n",
    "df_train.dropna(inplace=True) # 드랍으로 널값제거"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 이진분류"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_이진분류 = copy.deepcopy(df_train[df_train !='E'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "전처리    0\n",
       "평가     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_이진분류.head(2)\n",
    "df_이진분류.dropna(inplace=True)\n",
    "df_이진분류.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split (\n",
    "    df_이진분류['전처리'],df_이진분류['평가'],test_size=0.25,random_state=2021\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((218401,), (72801,), (218401,), (72801,))"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape,X_test.shape,y_train.shape,y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 타겟값 라벨링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_label = LabelEncoder().fit_transform(y_train)\n",
    "y_test_label = LabelEncoder().fit_transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1, 0, 1, ..., 0, 1, 0]), array([1, 1, 0, ..., 1, 1, 1]))"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_label,y_test_label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CV binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer()"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cvect_binary =  CountVectorizer()\n",
    "cvect_binary.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_cv_binary = cvect_binary.transform(X_train)\n",
    "X_test_cv_binary =  cvect_binary.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TF-IDF binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "tvect_binary = TfidfVectorizer(ngram_range=(1,2), max_df = 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 53s, sys: 696 ms, total: 2min 53s\n",
      "Wall time: 2min 53s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(max_df=0.9, ngram_range=(1, 2))"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time tvect_binary.fit(X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 16.1 s, sys: 123 ms, total: 16.3 s\n",
      "Wall time: 16.3 s\n",
      "CPU times: user 5.22 s, sys: 23.7 ms, total: 5.24 s\n",
      "Wall time: 5.26 s\n"
     ]
    }
   ],
   "source": [
    "%time X_train_tv_binary = tvect_binary.transform(X_train)\n",
    "%time X_test_tv_binary = tvect_binary.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 다중분류"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "XX_train,XX_test,yy_train,yy_test = train_test_split (\n",
    "    df_train['전처리'],df_train['평가'],test_size=0.25,random_state=2021\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((296083,), (98695,), (296083,), (98695,))"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XX_train.shape,XX_test.shape,yy_train.shape,yy_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### cv "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer()"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cvect  = copy.deepcopy(CountVectorizer())\n",
    "cvect.fit(XX_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_cv = cvect.transform(XX_train)\n",
    "X_test_cv=  cvect.transform(XX_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "tvect = copy.deepcopy(TfidfVectorizer(ngram_range=(1,2), max_df = 0.9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 8s, sys: 844 ms, total: 3min 9s\n",
      "Wall time: 3min 8s\n",
      "CPU times: user 18.4 s, sys: 147 ms, total: 18.5 s\n",
      "Wall time: 18.6 s\n",
      "CPU times: user 5.86 s, sys: 35.8 ms, total: 5.9 s\n",
      "Wall time: 5.9 s\n"
     ]
    }
   ],
   "source": [
    "%time tvect.fit(XX_train)\n",
    "%time XX_train_tv = tvect.transform(XX_train)\n",
    "%time XX_test_tv = tvect.transform(XX_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 비교 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "ests =[lr,nb,xgc,svc,knn,rfc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for est in ests:\n",
    "    est.fit(X_train_cv_binary,y_train)\n",
    "    print(est.score(X_test_cv,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def auto(model,vect,i):\n",
    "    g= globals()\n",
    "    if vect == 'cvect':\n",
    "        g[f'{vect}{i}'] = CountVectorizer(stop_words='english',ngram_range=(1,i))\n",
    "    elif vect == 'tvect':\n",
    "        g[f'{vect}{i}'] = TfidfVectorizer(stop_words='english',ngram_range=(1,i))\n",
    "    g[f'{vect}{i}'].fit(X_train)\n",
    "    g[f'X_train_{vect}{i}'] = g[f'{vect}{i}'].transform(X_train)\n",
    "    g[f'X_test_{vect}{i}'] = g[f'{vect}{i}'].transform(X_test)\n",
    "    model.fit(g[f'X_train_{vect}{i}'],y_train)\n",
    "    return model.score(g[f'X_test_{vect}{i}'],y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/miwoos/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모델:LogisticRegression()\t,벡터:cvect\tngram_range:1일때:0.8927761981291465입니다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/miwoos/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모델:LogisticRegression()\t,벡터:cvect\tngram_range:2일때:0.8896443730168542입니다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/miwoos/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모델:LogisticRegression()\t,벡터:tvect\tngram_range:1일때:0.891732256425049입니다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/miwoos/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모델:LogisticRegression()\t,벡터:tvect\tngram_range:2일때:0.8848642188980921입니다.\n",
      "모델:MultinomialNB()\t,벡터:cvect\tngram_range:1일때:0.7300311808903723입니다.\n",
      "모델:MultinomialNB()\t,벡터:cvect\tngram_range:2일때:0.7680251644894988입니다.\n",
      "모델:MultinomialNB()\t,벡터:tvect\tngram_range:1일때:0.7848793285806513입니다.\n",
      "모델:MultinomialNB()\t,벡터:tvect\tngram_range:2일때:0.7220093130588866입니다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/miwoos/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:14:56] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "모델:XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None)\t,벡터:cvect\tngram_range:1일때:0.8649331739948627입니다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/miwoos/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:18:23] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "모델:XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=1, enable_categorical=False,\n",
      "              gamma=0, gpu_id=-1, importance_type=None,\n",
      "              interaction_constraints='', learning_rate=0.300000012,\n",
      "              max_delta_step=0, max_depth=6, min_child_weight=1, missing=nan,\n",
      "              monotone_constraints='()', n_estimators=100, n_jobs=16,\n",
      "              num_parallel_tree=1, predictor='auto', random_state=0,\n",
      "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
      "              tree_method='exact', validate_parameters=1, verbosity=None)\t,벡터:cvect\tngram_range:2일때:0.865523825222181입니다.\n"
     ]
    }
   ],
   "source": [
    "for model in [lr,nb,xgc,svc,knn,rfc]:\n",
    "    for vect in ['cvect','tvect']:\n",
    "            for i in [1,2]:\n",
    "                    print(f'모델:{model}\\t,벡터:{vect}\\tngram_range:{i}일때:{auto(model,vect,i)}입니다.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def auto2(model,vect,i):\n",
    "    g= globals()\n",
    "    if vect == 'cvect':\n",
    "        g[f'{vect}{i}'] = CountVectorizer(ngram_range=(1,i))\n",
    "    elif vect == 'tvect':\n",
    "        g[f'{vect}{i}'] = TfidfVectorizer(ngram_range=(1,i))\n",
    "    g[f'{vect}{i}'].fit(X_train)\n",
    "    g[f'XX_train_{vect}{i}'] = g[f'{vect}{i}'].transform(XX_train)\n",
    "    g[f'XX_test_{vect}{i}'] = g[f'{vect}{i}'].transform(XX_test)\n",
    "    model.fit(g[f'XX_train_{vect}{i}'],y_train_label)\n",
    "    return model.score(g[f'XX_test_{vect}{i}'],y_test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in [lr,nb,xgc,svc,knn,rfc]:\n",
    "    for vect in ['cvect','tvect']:\n",
    "            for i in [1,2]:\n",
    "                    print(f'다중분류 모델:{model}\\t,벡터:{vect}\\tngram_range:{i}일때:{auto2(model,vect,i)}입니다.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in [lr,nb,xgc,svc,knn,rfc]:\n",
    "    for test in [X_test_cv_binary,X_test_tv_binary,XX_test_cv,XX_test_tv]:\n",
    "        pred=model.predict(test)\n",
    "        if test in [X_test_cv_binary,X_test_tv_binary]:\n",
    "            ave = 'binary'\n",
    "        else:\n",
    "            ave = 'macro'\n",
    "        accuracy_score(y_test_label, pred)\n",
    "        p = precision_score(y_test_label, pred,average=ave)\n",
    "        print(model'일떄'+test'이면'+'p는'p'입니다')\n",
    "        r = recall_score(y_test_label, pred,average=ave)\n",
    "        print(model'일떄'+test'이면'+'r는'r'입니다')\n",
    "        f1 = f1_score(y_test_label, pred,average=ave)\n",
    "        print(model'일떄'+test'이면'+'p는'f1'입니다'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
