{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UseLib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "############## 전처리 및 데이터 핸들링 ###############################\n",
    "\n",
    "import numpy as np\n",
    "import  pandas as pd\n",
    "import os\n",
    "from konlpy.tag import Okt \n",
    "okt = Okt()\n",
    "from tqdm.notebook import tqdm\n",
    "import joblib\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import copy\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "\n",
    "############## 머신러닝 모델#########################\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "nb = MultinomialNB()\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression()\n",
    "from sklearn.svm import SVC\n",
    "svc =  SVC()\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn =KNeighborsClassifier()\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc = RandomForestClassifier(random_state=2021)\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "xgc = XGBClassifier()\n",
    "\n",
    "\n",
    "############## 평가 ###############################\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UseData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/miwoos/WorkSpace/GoogleDrive/제주_전기차/data\n"
     ]
    }
   ],
   "source": [
    "cd ~/WorkSpace/GoogleDrive/제주_전기차/data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \u001b[0m\u001b[01;35melc_usewordcloud.png\u001b[0m             '전기차 동호회 전기차크롤링.csv'\n",
      " elecafe.csv                       전기차_전처리및토큰화.csv\n",
      " lr.pkl                            전기차관련검색어인기순.csv\n",
      " lrc.pkl                           전기차관심도지역.csv\n",
      " tvect.pkl                         전기차관심증가.csv\n",
      " 관련키워드.csv                    전기차전처리추가.csv\n",
      " 네이버-제주전기차후기통합.csv     전기차키워드관련주제인기순.csv\n",
      " 느영나영전기차크롤링.csv          전체본문의댓글결과_2022.03.06.xlsx\n",
      " 느영나영전기차크롤링.csv.part     제사모크롤링.csv\n",
      "'본문 검색 결과_2022.03.06.xlsx'   투플럭스sjeju.csv\n",
      " \u001b[01;35m빈도수파악.png\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "ls ## 데이터 위치 파악 및 데이터 리스트 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train= pd.read_csv('전기차_전처리및토큰화.csv')\n",
    "df_cafe = pd.read_csv('elecafe.csv')\n",
    "df_Blog = pd.read_csv('네이버-제주전기차후기통합.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 러닝"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 널값 제거 및 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>전처리</th>\n",
       "      <th>평가</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>아이오 닉 휠 베이스 가치 서비스 센터 가다 부품 수급 문제 로 렌터카 받다 오다 ...</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>현대차 아이오 닉 테슬라 모델 뭘 살다 요 현대차 아이오 닉 테슬라 모델 뭘 살다 ...</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 전처리 평가\n",
       "0  아이오 닉 휠 베이스 가치 서비스 센터 가다 부품 수급 문제 로 렌터카 받다 오다 ...  P\n",
       "1  현대차 아이오 닉 테슬라 모델 뭘 살다 요 현대차 아이오 닉 테슬라 모델 뭘 살다 ...  P"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전처리    0\n",
      "평가     0\n",
      "dtype: int64\n",
      "제목      0\n",
      "내용      0\n",
      "댓글      0\n",
      "유형      0\n",
      "조회수     0\n",
      "작성날짜    0\n",
      "월별      0\n",
      "카페명     0\n",
      "년별      0\n",
      "dtype: int64\n",
      "제목      0\n",
      "날짜      0\n",
      "내용      0\n",
      "href    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df_train.isnull().sum())\n",
    "print(df_cafe.isnull().sum())\n",
    "print(df_Blog.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df_Blog['index'] # 인덱스칼럼이 널값이많아서 컬럼 자체를 없애 버림 \n",
    "df_train.dropna(inplace=True) # 드랍으로 널값제거"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 이진분류"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_이진분류 = copy.deepcopy(df_train[df_train !='E'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "전처리    0\n",
       "평가     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_이진분류.head(2)\n",
    "df_이진분류.dropna(inplace=True)\n",
    "df_이진분류.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split (\n",
    "    df_이진분류['전처리'],df_이진분류['평가'],test_size=0.25,random_state=2021\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((218401,), (72801,), (218401,), (72801,))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape,X_test.shape,y_train.shape,y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 타겟값 라벨링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_label = LabelEncoder().fit_transform(y_train)\n",
    "y_test_label = LabelEncoder().fit_transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1, 0, 1, ..., 0, 1, 0]), array([1, 1, 0, ..., 1, 1, 1]))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_label,y_test_label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CV binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer()"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cvect_binary =  CountVectorizer()\n",
    "cvect_binary.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_cv_binary = cvect_binary.transform(X_train)\n",
    "X_test_cv_binary =  cvect_binary.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TF-IDF binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "tvect_binary = TfidfVectorizer(ngram_range=(1,2), max_df = 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 51s, sys: 901 ms, total: 2min 52s\n",
      "Wall time: 2min 52s\n",
      "CPU times: user 18.1 s, sys: 112 ms, total: 18.2 s\n",
      "Wall time: 18.2 s\n",
      "CPU times: user 6.28 s, sys: 16 ms, total: 6.3 s\n",
      "Wall time: 6.3 s\n"
     ]
    }
   ],
   "source": [
    "%time tvect_binary.fit(X_train)\n",
    "%time X_train_tv_binary = tvect_binary.transform(X_train)\n",
    "%time X_test_tv_binary = tvect_binary.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 다중분류"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "XX_train,XX_test,yy_train,yy_test = train_test_split (\n",
    "    df_train['전처리'],df_train['평가'],test_size=0.25,random_state=2021\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((296083,), (98695,), (296083,), (98695,))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XX_train.shape,XX_test.shape,yy_train.shape,yy_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### cv "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(max_df=0.9, ngram_range=(1, 2))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cvect  = copy.deepcopy(CountVectorizer(ngram_range=(1,2), max_df = 0.9))\n",
    "cvect.fit(XX_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "XX_train_cv = cvect.transform(XX_train)\n",
    "XX_test_cv=  cvect.transform(XX_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "tvect = copy.deepcopy(TfidfVectorizer(ngram_range=(1,2), max_df = 0.9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 8s, sys: 875 ms, total: 3min 9s\n",
      "Wall time: 3min 8s\n",
      "CPU times: user 19.1 s, sys: 136 ms, total: 19.2 s\n",
      "Wall time: 19.3 s\n",
      "CPU times: user 6.13 s, sys: 31.9 ms, total: 6.16 s\n",
      "Wall time: 6.17 s\n"
     ]
    }
   ],
   "source": [
    "%time tvect.fit(XX_train)\n",
    "%time XX_train_tv = tvect.transform(XX_train)\n",
    "%time XX_test_tv = tvect.transform(XX_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 비교 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<98695x2633524 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 7118598 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XX_test_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def auto(model,train_test):\n",
    "    model.fit(train_test[0],y_train_label)\n",
    "    pred=model.predict(train_test[1])\n",
    "    if train_test[1] in [X_test_cv_binary,X_test_tv_binary]:\n",
    "        ave = 'binary'\n",
    "    else:\n",
    "        ave = 'macro'\n",
    "    accuracy_score(y_test_label, pred)\n",
    "    p = precision_score(y_test_label, pred,average=ave)\n",
    "    r = recall_score(y_test_label, pred,average=ave)\n",
    "    f1 = f1_score(y_test_label, pred,average=ave)\n",
    "    return f'스코어:{model.score(train_test[1],y_test_label)}\\nP:{p}\\nR:{r}\\nF1:{f1}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/miwoos/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모델:LogisticRegression()\n",
      "벡터:  (0, 2432197)\t0.07910994962304096\n",
      "  (0, 2431052)\t0.05319167306602463\n",
      "  (0, 2354383)\t0.10405430013221124\n",
      "  (0, 2354345)\t0.09592091283847538\n",
      "  (0, 2328319)\t0.10566444078329791\n",
      "  (0, 2327961)\t0.06005209669410858\n",
      "  (0, 2304510)\t0.08559064940959396\n",
      "  (0, 2301954)\t0.07325973788326424\n",
      "  (0, 2299568)\t0.06099968865252812\n",
      "  (0, 2295287)\t0.08210344821997043\n",
      "  (0, 2292101)\t0.09014923709822913\n",
      "  (0, 2288578)\t0.0634252631476161\n",
      "  (0, 2244820)\t0.12738470410986308\n",
      "  (0, 2244748)\t0.07648871630394954\n",
      "  (0, 2219921)\t0.06455300186148799\n",
      "  (0, 2219806)\t0.04552095185854805\n",
      "  (0, 2219597)\t0.05300152218378307\n",
      "  (0, 2219078)\t0.11516373202360683\n",
      "  (0, 2172263)\t0.12738470410986308\n",
      "  (0, 2172201)\t0.13161988396047292\n",
      "  (0, 2172114)\t0.093353107966973\n",
      "  (0, 2172017)\t0.07384297295745064\n",
      "  (0, 2172008)\t0.239485552751769\n",
      "  (0, 2112182)\t0.07643555975803376\n",
      "  (0, 2110991)\t0.04587027677374313\n",
      "  :\t:\n",
      "  (72799, 705925)\t0.19039360074343262\n",
      "  (72799, 705694)\t0.15651049760340488\n",
      "  (72799, 705387)\t0.1252755312539558\n",
      "  (72799, 705155)\t0.19871716115602772\n",
      "  (72799, 704847)\t0.180816011861024\n",
      "  (72799, 703839)\t0.3468355198447644\n",
      "  (72799, 541913)\t0.18273520731100376\n",
      "  (72799, 541296)\t0.09304609561583432\n",
      "  (72799, 493683)\t0.180816011861024\n",
      "  (72799, 493668)\t0.13182251706836487\n",
      "  (72799, 72960)\t0.042414699086070526\n",
      "  (72800, 2273358)\t0.3582951640336272\n",
      "  (72800, 2273104)\t0.25909095899671597\n",
      "  (72800, 2078284)\t0.2961409718146658\n",
      "  (72800, 2078033)\t0.17860831919356607\n",
      "  (72800, 1526565)\t0.38363016791999643\n",
      "  (72800, 1524656)\t0.13750087189009544\n",
      "  (72800, 971752)\t0.22352345322626124\n",
      "  (72800, 971690)\t0.20153854383085748\n",
      "  (72800, 815807)\t0.2831106696397586\n",
      "  (72800, 815791)\t0.15514013771157845\n",
      "  (72800, 582796)\t0.40233085981796485\n",
      "  (72800, 581844)\t0.25911929071057693\n",
      "  (72800, 61887)\t0.22116983921853553\n",
      "  (72800, 61848)\t0.2146806704621274일때\n",
      "스코어:0.8927761981291465\n",
      "P:0.9134650887114013\n",
      "R:0.9334180583411108\n",
      "F1:0.9233337916674852입니다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/miwoos/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "for model in [lr,nb,svc,knn,rfc]:\n",
    "    for train_test in [[X_train_cv_binary,X_test_cv_binary],[X_train_tv_binary,X_test_tv_binary]]:\n",
    "        print(f'모델:{model}\\n벡터:{test}일때\\n{auto(model,train_test)}입니다.')\n",
    "        results.append(f'모델:{model}\\n벡터:{test}일때\\n{auto(model,train_test)}입니다.')\n",
    "    for train_test in [[XX_train_cv,XX_test_cv],[XX_train_tv,XX_test_tv]]:\n",
    "        print(f'모델:{model}\\n,벡터:{test}일때\\n{auto(model,train_test)}입니다.')\n",
    "        results.append(f'다중분류모델:{model}\\n벡터:{test}일때\\n{auto(model,train_test)}입니다.')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def auto2(model,vect,i):\n",
    "#     g= globals()\n",
    "#     if vect == 'cvect':\n",
    "#         g[f'{vect}{i}'] = CountVectorizer(ngram_range=(1,i))\n",
    "#     elif vect == 'tvect':\n",
    "#         g[f'{vect}{i}'] = TfidfVectorizer(ngram_range=(1,i))\n",
    "#     g[f'{vect}{i}'].fit(X_train)\n",
    "#     g[f'XX_train_{vect}{i}'] = g[f'{vect}{i}'].transform(XX_train)\n",
    "#     g[f'XX_test_{vect}{i}'] = g[f'{vect}{i}'].transform(XX_test)\n",
    "#     model.fit(g[f'XX_train_{vect}{i}'],y_train_label)\n",
    "#     return model.score(g[f'XX_test_{vect}{i}'],y_test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !mkdir model\n",
    "# for model in [lr,nb,xgc,svc,knn,rfc]:\n",
    "#     for vect in ['cvect','tvect']:\n",
    "#             for i in [1,2]:\n",
    "#                     print(f'다중분류 모델:{model}\\t,벡터:{vect}\\tngram_range:{i}일때:{auto2(model,vect,i)}입니다.')\n",
    "#                     joblib.dump(model,f'다중분류model/전기차{vect}{model}ngram{i}.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in [lr,nb,svc,knn,rfc]:\n",
    "    for test in [X_test_cv_binary,X_test_tv_binary,XX_test_tv,XX_test_tv]:\n",
    "        pred=model.predict(test)\n",
    "        if test in [X_test_cv_binary,X_test_tv_binary]:\n",
    "            ave = 'binary'\n",
    "        else:\n",
    "            ave = 'macro'\n",
    "        accuracy_score(y_test_label, pred)\n",
    "        p = precision_score(y_test_label, pred,average=ave)\n",
    "        print(f'{model}일떄+{test}이면+{p}는p입니다')\n",
    "        r = recall_score(y_test_label, pred,average=ave)\n",
    "        print(f'{model}일떄+{test}이면+{r}는r입니다')\n",
    "        f1 = f1_score(y_test_label, pred,average=ave)\n",
    "        print(f'{model}일떄+{test}이면+{f1}는f1입니다')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 모델저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !mkdir model\n",
    "# for model in [lr,nb,xgc,svc,knn,rfc]:\n",
    "#     joblib.dump(model,f'model/전기차{model}.pkl')\n",
    "for vect in [cvect_binary,tvect_binary,cvect,tvect]:\n",
    "    joblib.dump(vect,f'model/전기차{vect}.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
